{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo\n",
    "* [Errno 2] No such file or directory: '../data/procecced/csv/race-2008.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/5d/98e804272715e9af20bf1bca5c7d26715d9e3bf47414b203c81a02dd1270/pandas-1.0.4-cp36-cp36m-macosx_10_9_x86_64.whl (10.2MB)\n",
      "\u001b[K     |████████████████████████████████| 10.2MB 277kB/s eta 0:00:01    |██████████████████████████▋     | 8.5MB 410kB/s eta 0:00:05\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /Users/gake0725/opt/python_env/py364env/lib/python3.6/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/gake0725/opt/python_env/py364env/lib/python3.6/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/gake0725/opt/python_env/py364env/lib/python3.6/site-packages (from pandas) (1.17.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gake0725/opt/python_env/py364env/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas) (1.13.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.0.4\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "race_htmlに含まれるhtmlを利用して、データを生成する\n",
    "\"\"\"\n",
    "import datetime\n",
    "import pytz\n",
    "now_datetime = datetime.datetime.now(pytz.timezone('Asia/Tokyo'))\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from os import path\n",
    "# OWN_FILE_NAME = path.splitext(path.basename(__file__))[0]\n",
    "RACR_URL_DIR = \"../data/raw/race_url\"\n",
    "RACR_HTML_DIR = \"../data/raw/race_html\"\n",
    "CSV_DIR = \"../data/procecced/csv\"\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger() #ファイルの名前を渡す\n",
    "\n",
    "YEAR_FROM = 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_data_columns=[\n",
    "    'race_id',\n",
    "    'race_round',\n",
    "    'race_title',\n",
    "    'race_course',\n",
    "    'weather',\n",
    "    'ground_status',\n",
    "    'time',\n",
    "    'date',\n",
    "    'where_racecourse',\n",
    "    'total_horse_number',\n",
    "    'frame_number_first',\n",
    "    'horse_number_first',\n",
    "    'frame_number_second',\n",
    "    'horse_number_second',\n",
    "    'frame_number_third',\n",
    "    'horse_number_third',\n",
    "    'tansyo',\n",
    "    'hukusyo_first',\n",
    "    'hukusyo_second',\n",
    "    'hukusyo_third',\n",
    "    'wakuren',\n",
    "    'umaren',\n",
    "    'wide_1_2',\n",
    "    'wide_1_3',\n",
    "    'wide_2_3',\n",
    "    'umatan',\n",
    "    'renhuku3',\n",
    "    'rentan3'\n",
    "    ]\n",
    "\n",
    "horse_data_columns=[\n",
    "    'race_id',\n",
    "    'rank',\n",
    "    'frame_number',\n",
    "    'horse_number',\n",
    "    'horse_id',\n",
    "    'sex_and_age',\n",
    "    'burden_weight',\n",
    "    'rider_id',\n",
    "    'goal_time',\n",
    "    'goal_time_dif',\n",
    "    'time_value',\n",
    "    'half_way_rank',\n",
    "    'last_time',\n",
    "    'odds',\n",
    "    'popular',\n",
    "    'horse_weight',\n",
    "    'tame_time',\n",
    "    'tamer_id',\n",
    "    'owner_id'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv_from_html():\n",
    "    for year in range(YEAR_FROM, now_datetime.year+1):\n",
    "        make_csv_from_html_by_year(year)\n",
    "\n",
    "def make_csv_from_html_by_year(year):\n",
    "    save_race_csv = CSV_DIR+\"/race-\"+str(year)+\".csv\"\n",
    "    horse_race_csv = CSV_DIR+\"/horse-\"+str(year)+\".csv\"\n",
    "    if not ((os.path.isfile(save_race_csv)) and (os.path.isfile(horse_race_csv))): # まだcsvがなければ生成\n",
    "        race_df = pd.DataFrame(columns=race_data_columns )\n",
    "        horse_df = pd.DataFrame(columns=horse_data_columns )\n",
    "        logger.info(\"saving csv (\" + str(year) +\")\")\n",
    "        total = 0;\n",
    "        for month in range(1, 13):\n",
    "            # race_html/year/month というディレクトリが存在すればappend, なければ何もしない\n",
    "            html_dir = RACR_HTML_DIR+\"/\"+str(year)+\"/\"+str(month)\n",
    "            if os.path.isdir(html_dir):\n",
    "                file_list = os.listdir(html_dir) # get all file names\n",
    "                total += len(file_list)\n",
    "                logger.info(\" appending \" + str(len(file_list)) + \" datas to csv (\" + str(year)  +\" \"+ str(month)+ \")\")\n",
    "                for file_name in file_list:\n",
    "                    with open(html_dir+\"/\"+file_name, \"r\") as f:\n",
    "                        html = f.read()\n",
    "                        list = file_name.split(\".\")\n",
    "                        race_id = list[-2]\n",
    "                        race_list, horse_list_list = get_rade_and_horse_data_by_html(race_id, html)\n",
    "                        for horse_list in horse_list_list:\n",
    "                            horse_se = pd.Series( horse_list, index=horse_df.columns)\n",
    "                            horse_df = horse_df.append(horse_se, ignore_index=True)\n",
    "                        race_se = pd.Series(race_list, index=race_df.columns )\n",
    "                        race_df = race_df.append(race_se, ignore_index=True )\n",
    "\n",
    "        race_df.to_csv(save_race_csv, header=True, index=False)\n",
    "        horse_df.to_csv(horse_race_csv, header=True, index=False)\n",
    "        logger.info(' (rows, columns) of race_df:\\t'+ str(race_df.shape))\n",
    "        logger.info(' (rows, columns) of horse_df:\\t'+ str(horse_df.shape))\n",
    "        logger.info(\"saved \" + str(total) + \" htmls to csv (\" + str(year) +\")\")\n",
    "    else:\n",
    "        logger.info(\"already have csv (\" + str(year) +\")\")\n",
    "\n",
    "def get_rade_and_horse_data_by_html(race_id, html):\n",
    "    race_list = [race_id]\n",
    "    horse_list_list = []\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # race基本情報\n",
    "    data_intro = soup.find(\"div\", class_=\"data_intro\")\n",
    "    race_list.append(data_intro.find(\"dt\").get_text().strip(\"\\n\")) # race_round\n",
    "    race_list.append(data_intro.find(\"h1\").get_text().strip(\"\\n\")) # race_title\n",
    "    race_details1 = data_intro.find(\"p\").get_text().strip(\"\\n\").split(\"\\xa0/\\xa0\")\n",
    "    race_list.append(race_details1[0]) # race_course\n",
    "    race_list.append(race_details1[1]) # weather\n",
    "    race_list.append(race_details1[2]) # ground_status\n",
    "    race_list.append(race_details1[3]) # time\n",
    "    race_details2 = data_intro.find(\"p\", class_=\"smalltxt\").get_text().strip(\"\\n\").split(\" \")\n",
    "    race_list.append(race_details2[0]) # date\n",
    "    race_list.append(race_details2[1]) # where_racecourse\n",
    "\n",
    "\n",
    "    result_rows = soup.find(\"table\", class_=\"race_table_01 nk_tb_common\").findAll('tr') # レース結果\n",
    "    # 上位3着の情報\n",
    "    race_list.append(len(result_rows)-1) # total_horse_number\n",
    "    for i in range(1,4):\n",
    "        row = result_rows[i].findAll('td')\n",
    "        race_list.append(row[1].get_text()) # frame_number_first or second or third\n",
    "        race_list.append(row[2].get_text()) # horse_number_first or second or third\n",
    "\n",
    "\n",
    "    # 払い戻し(単勝・複勝・三連複・3連単)\n",
    "    pay_back_tables = soup.findAll(\"table\", class_=\"pay_table_01\")\n",
    "\n",
    "    pay_back1 = pay_back_tables[0].findAll('tr') # 払い戻し1(単勝・複勝)\n",
    "    race_list.append(pay_back1[0].find(\"td\", class_=\"txt_r\").get_text()) #tansyo\n",
    "    hukuren = pay_back1[1].find(\"td\", class_=\"txt_r\")\n",
    "    tmp = []\n",
    "    for string in hukuren.strings:\n",
    "        tmp.append(string)\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            race_list.append(tmp[i]) # hukuren_first or second or third\n",
    "        except IndexError:\n",
    "            race_list.append(\"0\")\n",
    "\n",
    "    # 枠連\n",
    "    try:\n",
    "        race_list.append(pay_back1[2].find(\"td\", class_=\"txt_r\").get_text())\n",
    "    except IndexError:\n",
    "        race_list.append(\"0\")\n",
    "\n",
    "    # 馬連\n",
    "    try:\n",
    "        race_list.append(pay_back1[3].find(\"td\", class_=\"txt_r\").get_text())\n",
    "    except IndexError:\n",
    "        race_list.append(\"0\")\n",
    "\n",
    "\n",
    "\n",
    "    pay_back2 = pay_back_tables[1].findAll('tr') # 払い戻し2(三連複・3連単)\n",
    "\n",
    "    # wide 1&2\n",
    "    wide = pay_back2[0].find(\"td\", class_=\"txt_r\")\n",
    "    tmp = []\n",
    "    for string in wide.strings:\n",
    "        tmp.append(string)\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            race_list.append(tmp[i]) # hukuren_first or second or third\n",
    "        except IndexError:\n",
    "            race_list.append(\"0\")\n",
    "\n",
    "    # umatan\n",
    "    race_list.append(pay_back2[1].find(\"td\", class_=\"txt_r\").get_text()) #umatan\n",
    "\n",
    "    race_list.append(pay_back2[2].find(\"td\", class_=\"txt_r\").get_text()) #renhuku3\n",
    "    try:\n",
    "        race_list.append(pay_back2[3].find(\"td\", class_=\"txt_r\").get_text()) #rentan3\n",
    "    except IndexError:\n",
    "        race_list.append(\"0\")\n",
    "\n",
    "    # horse data\n",
    "    for rank in range(1, len(result_rows)):\n",
    "        horse_list = [race_id]\n",
    "        result_row = result_rows[rank].findAll(\"td\")\n",
    "        # rank\n",
    "        horse_list.append(result_row[0].get_text())\n",
    "        # frame_number\n",
    "        horse_list.append(result_row[1].get_text())\n",
    "        # horse_number\n",
    "        horse_list.append(result_row[2].get_text())\n",
    "        # horse_id\n",
    "        horse_list.append(result_row[3].find('a').get('href').split(\"/\")[-2])\n",
    "        # sex_and_age\n",
    "        horse_list.append(result_row[4].get_text())\n",
    "        # burden_weight\n",
    "        horse_list.append(result_row[5].get_text())\n",
    "        # rider_id\n",
    "        horse_list.append(result_row[6].find('a').get('href').split(\"/\")[-2])\n",
    "        # goal_time\n",
    "        horse_list.append(result_row[7].get_text())\n",
    "        # goal_time_dif\n",
    "        horse_list.append(result_row[8].get_text())\n",
    "        # time_value(premium)\n",
    "        horse_list.append(result_row[9].get_text())\n",
    "        # half_way_rank\n",
    "        horse_list.append(result_row[10].get_text())\n",
    "        # last_time(上り)\n",
    "        horse_list.append(result_row[11].get_text())\n",
    "        # odds\n",
    "        horse_list.append(result_row[12].get_text())\n",
    "        # popular\n",
    "        horse_list.append(result_row[13].get_text())\n",
    "        # horse_weight\n",
    "        horse_list.append(result_row[14].get_text())\n",
    "        # tame_time(premium)\n",
    "        horse_list.append(result_row[15].get_text())\n",
    "        # 16:コメント、17:備考\n",
    "        # tamer_id\n",
    "        horse_list.append(result_row[18].find('a').get('href').split(\"/\")[-2])\n",
    "        # owner_id\n",
    "        horse_list.append(result_row[19].find('a').get('href').split(\"/\")[-2])\n",
    "\n",
    "        horse_list_list.append(horse_list)\n",
    "\n",
    "    return race_list, horse_list_list\n",
    "\n",
    "\n",
    "\n",
    "#def update_csv():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/procecced/csv/race-2008.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-86c88e98f29d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     logger.info(\"start making csv!\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmake_csv_from_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# テスト\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-4d4adeefb707>\u001b[0m in \u001b[0;36mmake_csv_from_html\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_csv_from_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYEAR_FROM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow_datetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mmake_csv_from_html_by_year\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_csv_from_html_by_year\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-4d4adeefb707>\u001b[0m in \u001b[0;36mmake_csv_from_html_by_year\u001b[0;34m(year)\u001b[0m\n\u001b[1;32m     30\u001b[0m                         \u001b[0mrace_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrace_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrace_se\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mrace_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_race_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mhorse_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhorse_race_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' (rows, columns) of race_df:\\t'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrace_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/python_env/py364env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m         )\n\u001b[0;32m-> 3204\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/python_env/py364env/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             )\n\u001b[1;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/python_env/py364env/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/procecced/csv/race-2008.csv'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "#     formatter = \"%(asctime)s [%(levelname)s]\\t%(message)s\" # フォーマットを定義\n",
    "#     #formatter_func = \"%(asctime)s\\t[%(levelname)8s]\\t%(message)s from %(func)\" # フォーマットを定義\n",
    "#     logging.basicConfig(filename='logfile/'+OWN_FILE_NAME+'.logger.log', level=logging.INFO, format=formatter)\n",
    "\n",
    "#     logger.info(\"start making csv!\")\n",
    "    make_csv_from_html()\n",
    "\n",
    "    # テスト\n",
    "#     make_csv_from_html_by_year(2008)\n",
    "    \"\"\"\n",
    "    with open(\"race_html/2008/1/200810010312.html\", \"r\") as f:\n",
    "        html = f.read()\n",
    "        get_rade_and_horse_data_by_html(200810010312,html)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
