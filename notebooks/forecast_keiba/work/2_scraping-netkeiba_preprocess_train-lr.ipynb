{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ収集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lxml\n",
    "# !pip install html5lib\n",
    "# !pip install bs4\n",
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプル確認\n",
    "url = 'https://db.netkeiba.com/race/202009030811/'\n",
    "\n",
    "print(type(pd.read_html(url)[0]))\n",
    "# -> df\n",
    "\n",
    "pd.read_html(url)[0]\n",
    "# -> \t着順\t枠番\t馬番\t馬名\t性齢\t斤量\t騎手\tタイム\t着差\t単勝\t人気\t馬体重\t調教師"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def scrape_race_results(race_id_list: list)-> dict:\n",
    "    \"\"\"\n",
    "    netkeiba.comのレースIDのリストを渡して、それらをまとめて{'レースID', 結果のDataFrame}という形式の辞書型に格納する\n",
    "    race_results['201901010101']\n",
    "    -> df 着順\t枠番\t馬番\t馬名\t性齢\t斤量\t騎手\tタイム\t着差\t単勝\t人気\t馬体重\t調教師\n",
    "    \"\"\"\n",
    "    race_results_dict = {}\n",
    "    for race_id in race_id_list:\n",
    "        try:\n",
    "            url = 'https://db.netkeiba.com/race/' + race_id\n",
    "            race_results_dict[race_id] = pd.read_html(url)[0]\n",
    "            time.sleep(0.1)\n",
    "        except IndexError:\n",
    "            continue\n",
    "        except:\n",
    "            break\n",
    "    return race_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race id を生成する（規則的に生成できる）\n",
    "# todo: 2019年に絞っている\n",
    "race_id_list = []\n",
    "\n",
    "for place in range(1,11):\n",
    "    for kai in range(1,6):\n",
    "        for day in range(1,9):\n",
    "            for r in range(1,13):\n",
    "                race_id = '2019' + str(place).zfill(2) + str(kai).zfill(2) + str(day).zfill(2) + str(r).zfill(2)\n",
    "                race_id_list.append(race_id)\n",
    "# -> ['201901010101', '201901010102', ,,, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: listを絞っている\n",
    "race_results_dict = scrape_race_results(race_id_list[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 表として見やすいように、dfのindexにrace idを入れる\n",
    "for key in race_results_dict.keys():\n",
    "    race_results_dict[key].index = [key]*len(race_results_dict[key])\n",
    "\n",
    "# 各レース結果のdfを1つに結合する\n",
    "race_results_df = pd.concat((race_results_dict[key] for key in race_results_dict.keys()),sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_results_df.to_pickle('../../../data/raw/race_results_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_results_df = pd.read_pickle('../../../data/raw/race_results_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_netkeiba_past(race_results_df):\n",
    "    df = race_results_df.copy()\n",
    "\n",
    "    # データ整形\n",
    "    df = df[~(df['着順'].astype(str).str.contains('\\D'))]\n",
    "    df['着順'] = df['着順'].astype(int)\n",
    "    df['性'] = df['性齢'].map(lambda x:str(x)[0])\n",
    "    df['年齢'] = df['性齢'].map(lambda x:str(x)[1:]).astype(int)\n",
    "    df['体重'] = df['馬体重'].str.split('(',expand = True)[0].astype(int)\n",
    "    df['体重変化'] = df['馬体重'].str.split('(',expand = True)[1].str[:-1].astype(int)\n",
    "    df['単勝'] = df['単勝'].astype(float)\n",
    "    \n",
    "    df.drop(['タイム','着差','調教師','性齢','馬体重'],axis = 1,inplace = True)\n",
    "\n",
    "    # 4位より下はまとめる\n",
    "    clip_rank = lambda x: x if x < 4 else 4\n",
    "    df['rank'] = df['着順'].map(clip_rank)\n",
    "\n",
    "    # test['馬名'].value_counts()などでカウントし、数が多そうなのは落とした後、ダミー変数化\n",
    "    df.drop(['着順','馬名'], axis = 1,inplace = True)\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_results_df_processed = preprocess_netkeiba_past(race_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_results_df_processed.to_pickle('../../../data/processed/race_results_df_processed.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_results_df_processed = pd.read_pickle('../../../data/processed/race_results_df_processed.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数の取得\n",
    "X = race_results_df_processed.drop(['rank'],axis=1)\n",
    "# 目的変数の取得\n",
    "y = race_results_df_processed['rank']\n",
    "\n",
    "# train と test に分離\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下記で学習もできるが、今回はunder samplingを追加するのでコメントアウトする\n",
    "# # 学習\n",
    "# model = LogisticRegression()\n",
    "# model.fit(X_train,y_train)\n",
    "# print('train score: ' + str(model.score(X_train,y_train)))\n",
    "# print('test score: ' + str(model.score(X_test,y_test)))\n",
    "\n",
    "# # テストデータでの予測結果を取得し、出力する\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(pd.DataFrame({'pred':y_pred,'actual':y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムアンダーサンプリング\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "cnt_rank_1 = y_train.value_counts()[1]\n",
    "cnt_rank_2 = y_train.value_counts()[2]\n",
    "cnt_rank_3 = y_train.value_counts()[3]\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy={1:cnt_rank_1,2:cnt_rank_2,3:cnt_rank_3,4:cnt_rank_1},random_state=71)\n",
    "\n",
    "X_train_rus,y_train_rus = rus.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_rus,y_train_rus)\n",
    "print('train score: ' + str(model.score(X_train,y_train)))\n",
    "print('test score: ' + str(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータでの予測結果を取得し、出力する\n",
    "y_pred = model.predict(X_test)\n",
    "print(pd.DataFrame({'pred':y_pred,'actual':y_test}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
